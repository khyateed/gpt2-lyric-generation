{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- compare verb/nouns \n",
    "- look at frequency of repeated words\n",
    "- number of stop words\n",
    "- free form prompts for empirical evaluation\n",
    "- look for common beatles themes (heartbreak, girl, dancing,)\n",
    "- syllable counts\n",
    "- compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def generate_text(sequence, max_length):\n",
    "    model_path = \"results\"\n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    return(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't let me down, don't let me down Don't let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I get high when I see you go by My oh my When ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[All too much!] It's all too much It's all to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love you, 'cause you tell me things I want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is there anybody going to listen to my story A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  Don't let me down, don't let me down Don't let...\n",
       "1  I get high when I see you go by My oh my When ...\n",
       "2   [All too much!] It's all too much It's all to...\n",
       "3  I love you, 'cause you tell me things I want t...\n",
       "4  Is there anybody going to listen to my story A..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet('testing_lyrics.parquet').reset_index(drop=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['input'] = test['lyrics'].apply(lambda x: ' '.join(x.split()[:50])) #50 tokens\n",
    "test['prediction'] = test['input'].apply(lambda x: generate_text(x,200))\n",
    "# test.to_parquet('predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_parquet('predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['lyrics_end'] = preds['lyrics'].apply(lambda x: ' '.join(x.split()[50:100]))\n",
    "preds['prediction_end'] = preds['prediction'].apply(lambda x: ' '.join(x.split()[50:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the end I'm a loser And I lost someone who's near to me I'm a loser And I'm not what I appear to be Although I laugh and I act like a clown Beneath this mask I am wearing a frown My tears are falling like rain from the sky\""
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['lyrics_end'][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the end I'm a loser And I'm not what I appear to be Of all the love I have won or have lost There is one love I should never have crossed She was a girl in a million, my friend I should have known she would win in the\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['prediction_end'][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEAU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['let', 'me', 'down', 'dont', 'let', 'me', 'down', 'dont', 'let', 'me', 'down', 'im', 'in', 'love', 'for', 'the', 'first', 'time', 'dont', 'you', 'know', 'its', 'gonna', 'last', 'its', 'a', 'love', 'that', 'lasts', 'forever', 'its', 'a', 'love', 'that', 'has', 'no', 'past', 'seeking', 'past', 'dont', 'let', 'me', 'down', 'dont', 'let', 'me', 'down', 'dont', 'let', 'me']\n",
      "['let', 'me', 'down', 'dont', 'let', 'me', 'down', 'dont', 'let', 'me', 'down', 'and', 'from', 'the', 'first', 'time', 'that', 'she', 'really', 'done', 'me', 'oh', 'she', 'done', 'me', 'yeah', 'she', 'done', 'me', 'oh', 'yeah', 'oh', 'yeah', 'oh', 'yeah', 'oh', 'yeah', 'imagine', 'im', 'in', 'love', 'with', 'you', 'its', 'easy', 'cos', 'i', 'know', 'ive', 'imagined']\n"
     ]
    }
   ],
   "source": [
    "print(preds['lyrics_end'][0].lower().replace(',','').replace('(','').replace(')','').replace(\"'\",'').split(' '))\n",
    "print(preds['prediction_end'][0].lower().replace(',','').replace('(','').replace(')','').replace(\"'\",'').split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [['hello', 'not', 'my', 'big']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2704451468820861,\n",
       " 0.7573260996605835,\n",
       " 0.4185180195193637,\n",
       " 1.6374957314724148e-78,\n",
       " 0.3569804363478891,\n",
       " 1.0,\n",
       " 0.8162735195826227,\n",
       " 0.054285521517746294,\n",
       " 0.7255295110702159,\n",
       " 0.9381103447512052,\n",
       " 1.0,\n",
       " 0.36483085104667456,\n",
       " 0.7730575253950128,\n",
       " 0.26611662785390383,\n",
       " 0.22704626973856634,\n",
       " 1.0,\n",
       " 0.53487753050603,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.15702128402250726,\n",
       " 0.8576907222981509,\n",
       " 1.072268715173723e-231,\n",
       " 0.3499287218249928,\n",
       " 0.958740481558872,\n",
       " 3.6723267991733874e-155,\n",
       " 0.3830543913117282,\n",
       " 0.1974438117016396,\n",
       " 0.24575159036693417,\n",
       " 0.15186599422096483,\n",
       " 1.0,\n",
       " 3.4486983131945593e-155,\n",
       " 0.896849229036064,\n",
       " 0.316937673914309,\n",
       " 0.6252029912577429]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    reference = [preds['lyrics_end'][i].lower().replace(',','').replace('(','').replace(')','').replace(\"'\",'').split(' ')]\n",
    "    candidate = preds['prediction_end'][i].lower().replace(',','').replace('(','').replace(')','').replace(\"'\",'').split(' ')\n",
    "    scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
